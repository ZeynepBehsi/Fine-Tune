# -*- coding: utf-8 -*-
"""Fine-tune_Learnig_Rate.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1WvKoidqNP_lUUpwvjIS5ybzOdatY9dBA
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import tensorflow as tf


"""# FIND OPTIMUM LEARNING RATE
- Start without determinatio learning rate and see result in the graph (graph of loss change according to teh change of learning rate). Just determine momentum
- Use Learning Rate Scheduler which is one of callbacks methods
- After seeing result, build model again

## 1. Build base line model for observation loss change accorind to LR change
"""

# Build model
model = tf.keras.models.Sequential([
    tf.keras.Input(shape = (window_size,)),
    tf.keras.layers.Dense(10, activation = "relu"),
    tf.keras.layers.Dense(10, activation = "relu"),
    tf.keras.layers.Dense(1)
])

"""### ðŸ”º Default learning rate during observation = 1e-8"""

# create learning rate scheduler
lr_schedule = tf.keras.callbacks.LearningRateScheduler(
    lambda epoch: 1e-8 * 10**(epoch / 20))

# compile model, don't determine learning rate
model.compile(loss = "mse",
              optimizer = tf.keras.optimizers.SGD(momentum=0.9))

# train model
history = model.fit(dataset, epochs = 100, callbacks = [lr_schedule])

# Graph for observation the change of loss according to the change of learning rate

lrs = 1e-8 * (10 ** (np.arange(100) / 20))

plt.figure(figsize=(10, 6))
plt.grid(True)
plt.semilogx(lrs, history.history["loss"])
plt.tick_params('both', length=10, width=1, which='both')
plt.axis([1e-8, 1e-3, 0, 300])

"""## Result: Choose learnign rate = 10^-6 = a.e - 6
 
